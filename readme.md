# 简介
本项目匹配vllm而诞生！
是一个基于gradio的webui
# 功能
单轮对话
多轮对话
对话轮数可配置
最大上下文长度可配置
模型参数可配置
自动统计设置的历史对话轮数范围内的token数，自动丢弃超出范围的部分，实现自动统计token的多轮对话。（此功能稳定，但有些延迟，按照自己需要设置不要太大。。）
# 安装
需要安装  gradio库   版本建议3.41.0 
需要安装  jieba库
2024年4月1日的最新版gradio库网友实测也可以使用。
# 配置
max_window_tokens = 3000 #设置上下文最大token数量。  比如3000   最好别设置太大，大了有延迟（后续会解决）
history_rounds = 16 # 记忆的对话轮数，0为单轮对话，不记忆历史记录；16为记忆十六轮对话，对于的忘记。根据自己需求来设置。
# 文件
runxqwen32b.py 运行这个文件之前，打开你的vllm，加载模型的时候使用"gpt-3.5-turbo" 之类的任意名称， 然后在runxqwen32b.py中填写对应的模型名称：model='gpt-3.5-turbo',   可以改成自己的名称，但需要对应。  
不限于qwen32b系列，可以是任何vllm加载模型
使用窍门：
用户可以多复制几个，文件名改成自己常用的模型名称。
比如qwen14b.py  qwen72b.py  yi60b.py等等。。。
# 注意
yi系列，要求截止符写[7] ,比如这样写：'stop_token_ids': [7]
其他模型貌似留空就行：'stop_token_ids': []
# enjoy！
